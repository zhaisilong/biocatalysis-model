#!/usr/bin/env python
"""Preprocess reactions for learning."""

from typing import List, Tuple
from pathlib import Path
from collections import Counter

from rich.progress import Progress, SpinnerColumn, TimeElapsedColumn

from utils import get_logger, iter_count
import click
import pandas as pd
from tqdm import trange

from rdkit.Chem import AllChem as rdk

from rxn_biocatalysis_tools import (
    EnzymaticReaction,
    tokenize_enzymatic_reaction_smiles,
    disable_rdkit_logging,
)

log = get_logger(__name__)



def process_reaction(
        rxn: EnzymaticReaction, min_atom_count: int = 4
) -> EnzymaticReaction:
    """Removing precursors from products, remove molecules that couldn't be parsed by RDKit
    and remove single atoms from productsself.

    Args:
        rxn: An enzymatic reaction
        min_atom_count: Remove molecules with a heavy atom count smaller than this from the reaction

    Returns:
        The processed enzymatic reaction
    """
    rxn.remove_precursors_from_products()
    rxn.remove_none()
    rxn.products = [
        product
        for product in rxn.products
        if product.GetNumHeavyAtoms() >= min_atom_count
    ]
    return rxn


def remove_from_products(
        rxn: EnzymaticReaction, smart_patterns: List[str], smiles: List[str]
) -> EnzymaticReaction:
    """Remove the supplied cofactors from the products.

    Args:
        rxn: An enzymatic reaction
        cofactors: A list of SMILES of cofactors

    Returns:
        The enzymatic reaction with the cofactors removed from the products
    """

    if len(rxn.products) == 1:
        return rxn

    for smart_pattern in smart_patterns:
        mol_pattern = rdk.MolFromSmarts(smart_pattern)

        rxn.products = [
            mol for mol in rxn.products if not mol.HasSubstructMatch(mol_pattern)
        ]

        if len(rxn.products) == 1:
            return rxn

    rxn.products = [mol for mol in rxn.products if rxn.mol_to_smiles(mol) not in smiles]

    return rxn


def print_sources(rxns: List[EnzymaticReaction], title: str) -> None:
    """Print the sources and numbers of reactions per source as a table.

    Args:
        rxns: A list of enzymatic reactions
        title: The title of the table
    """
    sources = [rxn.source for rxn in rxns]

    print(f"\n\n{title}:")
    for key, value in dict(Counter(sources)).items():
        print(f"{key} -", str(value))

    print("Total:", len(rxns))


def write_splits(df: pd.DataFrame, ec_level: int, output_dir: Path) -> None:
    """Writing the training, validation, and testing src and tgt splits for a given EC level into a given output directory.

    Args:
        df: A pandas DataFrame containing the reaction strings as well as a field "ec_3" to grup the reactions by.
        ec_level: The EC level to be exported (0 to 4)
        output_dir: The path to the directory the outputs will be written to.
    """
    df_internal = df.copy()
    splits = {}
    splits["train"] = pd.DataFrame(columns=df_internal.columns, dtype='object')
    splits["valid"] = pd.DataFrame(columns=df_internal.columns, dtype='object')
    splits["test"] = pd.DataFrame(columns=df_internal.columns, dtype='object')

    df_internal[["rxn_str"]].to_csv(
        Path(output_dir, "combined.txt"), header=False, index=False
    )

    # Get the training set from reactions with unique productsÂ¨
    prod_val_cnts = df_internal.products.value_counts()
    df_unique_prods = df_internal[
        df_internal.products.isin(prod_val_cnts.index[prod_val_cnts.eq(1)])
    ]
    df_internal.drop(df_unique_prods.index, inplace=True)

    # Always group by x.x.x.- for splits to have a good coverage and
    # not miss sub-sub-classes
    for ec in df_internal.ec_1.unique():
        df_subset = df_internal[df_internal.ec_1 == ec]
        df_unique_prods_subset = df_unique_prods[df_unique_prods.ec_1 == ec]

        # Get 5% (of total) from rxns with unique products for test set
        n_total = len(df_subset) + len(df_unique_prods_subset)
        n_samples = round(n_total * 0.05)
        df_test = df_unique_prods_subset.sample(
            n=min(n_samples, len(df_unique_prods_subset)), random_state=42
        )
        df_unique_prods_subset.drop(df_test.index, inplace=True)

        # Join again to get training and validation sets
        df_subset = df_subset.append(df_unique_prods_subset)

        df_valid = df_subset.sample(n=n_samples, random_state=42)
        df_subset.drop(df_valid.index, inplace=True)

        splits["train"] = splits["train"].append(df_subset, ignore_index=True)
        splits["valid"] = splits["valid"].append(df_valid, ignore_index=True)
        splits["test"] = splits["test"].append(df_test, ignore_index=True)

    for key, value in splits.items():
        value["reactants"].to_csv(
            Path(output_dir, f"src-{key}.txt"), header=False, index=False
        )
        value["products"].to_csv(
            Path(output_dir, f"tgt-{key}.txt"), header=False, index=False
        )


@click.command()
@click.argument("input_files", type=click.Path(exists=True), nargs=-1)
@click.argument("output_path", type=click.Path(exists=True), nargs=1)
@click.option(
    "--remove-patterns",
    "remove_patterns_path",
    type=click.Path(exists=True),
    help="A file containing SMARTS patterns (one per line); molecules which match a pattern will be removed from the products",
)
@click.option(
    "--remove-molecules",
    "remove_molecules_path",
    type=click.Path(exists=True),
    help="A file containing molecules encoded as SMILES (one per line) to be removed from the products",
)
@click.option(
    "--ec-level",
    "ec_levels",
    multiple=True,
    type=int,
    default=[3],
    show_default=True,
    help="The EC level(s) to produce files for. This option can be repeated for multiple levels (--ec-level 1 --ec-level 2 ...)",
)
@click.option(
    "--max-products",
    "max_products",
    type=int,
    default=1,
    show_default=True,
    help="The maximum number of product molecules allowed in a reaction",
)
@click.option(
    "--min-atom-count",
    "min_atom_count",
    type=int,
    default=4,
    show_default=True,
    help="The minimum atom count of a molecule (molecules with less atoms are removed from the reactions)",
)
@click.option(
    "--bi-directional",
    "bi_directional",
    is_flag=True,
    help="Consider all reactions to be bi-directional",
)
@click.option(
    "--split-products",
    "split_products",
    is_flag=True,
    help="Wheter to split reactions with multiple products into multiple reactions with one product",
)
def main(
        input_files: str,
        output_path: str,
        remove_patterns_path: str,
        remove_molecules_path: str,
        ec_levels: Tuple[int, ...],
        max_products: int,
        min_atom_count: int,
        bi_directional: bool,
        split_products: bool,
):
    disable_rdkit_logging()
    remove_patterns = []
    remove_molecules = []

    if remove_patterns_path:
        for line in open(remove_patterns_path):
            if not line.startswith("//") and line.strip():
                remove_patterns.append(line.split("//")[0].strip())

    if remove_molecules_path:
        for line in open(remove_molecules_path):
            if not line.startswith("//") and line.strip():
                smiles = line.split("//")[0].strip()
                mol = rdk.MolFromSmiles(smiles)
                if mol:
                    remove_molecules.append(rdk.MolToSmiles(mol))

    enzymatic_reactions = []

    for input_file in input_files:
        source = Path(input_file).stem
        line_count = sum([1 for line in open(input_file, "r")])

        with open(input_file, "r") as f:
            with Progress(SpinnerColumn(), *Progress.get_default_columns(), "Elapsed:",
                          TimeElapsedColumn()) as progress:
                for line in progress.track(f, total=iter_count(input_file), description=f"Parsing {source}..."):
                    rxn = EnzymaticReaction(line.strip(), canonical=True, source=source)
                    enzymatic_reactions.append(rxn)
                    if bi_directional:
                        enzymatic_reactions.append(rxn.reverse())
        log.info("Done.\n")

    print_sources(enzymatic_reactions, "Parsed Reactions")

    with Progress(SpinnerColumn(), *Progress.get_default_columns(), "Elapsed:", TimeElapsedColumn()) as progress:
        for i, rxn in progress.track(enumerate(enzymatic_reactions), total=len(enzymatic_reactions),
                                     description=f"Processing reactions..."):
            enzymatic_reactions[i] = process_reaction(rxn, min_atom_count)
    log.info("Done.\n")

    with Progress(SpinnerColumn(), *Progress.get_default_columns(), "Elapsed:", TimeElapsedColumn()) as progress:
        for i, rxn in progress.track(enumerate(enzymatic_reactions), total=len(enzymatic_reactions),
                                     description="Removing patterns and molecules..."):
            enzymatic_reactions[i] = remove_from_products(
                rxn, remove_patterns, remove_molecules
            )
    log.info("Done.\n")

    if split_products:
        split_enzymatic_reactions = []
        with Progress(SpinnerColumn(), *Progress.get_default_columns(), "Elapsed:", TimeElapsedColumn()) as progress:
            for rxn in progress.track(enzymatic_reactions, total=len(enzymatic_reactions),
                                      description="Splitting multi-product reactions into multiple one-product reactions..."):
                if len(rxn.products) == 1:
                    split_enzymatic_reactions.append(rxn)
                else:
                    for product in rxn.get_products_as_smiles():
                        split_enzymatic_reactions.append(
                            EnzymaticReaction.from_smarts_and_ec(
                                ".".join(rxn.get_reactants_as_smiles()) + ">>" + product,
                                rxn.get_ec(),
                                source=rxn.source,
                            )
                        )
        enzymatic_reactions = split_enzymatic_reactions
        log.info("Done.\n")

    log.info(
        f"Removing reactions with less than 2 reactants or more than {max_products} product(s)..."
    )

    enzymatic_reactions = [rxn for rxn in enzymatic_reactions if
                           len(rxn.reactants) > 0 and len(rxn.products) <= max_products and len(rxn.products) > 0]

    log.info("Done.\n")

    log.info("Ordering molecules on both sides of the reactions...")
    for rxn in enzymatic_reactions:
        rxn.sort()
    log.info("Done.")

    print_sources(enzymatic_reactions, "Reactions after Filtering")

    df = pd.DataFrame({"rxn": enzymatic_reactions})

    log.info("Processing reactions for export...")

    cols = {}

    cols["rxn_str"] = []
    cols["ec"] = []
    cols["source"] = []

    for ec_level in range(1, 5):
        cols[f"ec_{ec_level}"] = []

    for ec_level in ec_levels:
        cols[f"rxn_str_ec{ec_level}"] = []
        cols[f"rxn_str_ec{ec_level}_tok"] = []

    for rxn in df.rxn:
        cols["rxn_str"].append(str(rxn))
        cols["ec"].append(rxn.get_ec())
        cols["source"].append(rxn.source)

        for ec_level in range(1, 5):
            cols[f"ec_{ec_level}"].append(rxn.get_ec(ec_level))

        for ec_level in ec_levels:
            rxn_str_level = rxn.to_string(ec_level)
            cols[f"rxn_str_ec{ec_level}"].append(rxn_str_level)

            cols[f"rxn_str_ec{ec_level}_tok"].append(
                tokenize_enzymatic_reaction_smiles(rxn_str_level, keep_pipe=True)
            )

    for key, value in cols.items():
        df[key] = value

    df = df[(df.ec != "") & (df.ec != " ")]
    df = df.drop_duplicates(subset=[f"rxn_str"], keep="first")

    log.info("Done.\n")
    print_sources(df.rxn, "Reactions after Deduplication")

    df[["rxn_str", "ec", "source"]].to_csv(
        Path(output_path, "combined_rxn_ec_sources.txt"), header=False, index=False
    )

    tasks = [f"exporting EC level {ec_level}" for ec_level in ec_levels]

    log.info("Exporting src and tgt files...")
    for ec_level in ec_levels:
        task = tasks.pop(0)

        df_tmp = df.copy()
        df_tmp = df_tmp.drop_duplicates(subset=[f"rxn_str_ec{ec_level}"], keep="first")

        # If someone finds a way on how to combne a split and assignment to two
        # columns with .loc, please change it. Otherwise surpress the warning
        # to get clean console output.
        pd.options.mode.chained_assignment = None

        df_tmp[["reactants", "products"]] = df_tmp[
            f"rxn_str_ec{ec_level}_tok"
        ].str.split(">>", expand=True)

        df_tmp.reactants = df_tmp.reactants.str.strip()
        df_tmp.products = df_tmp.products.str.strip()

        parent_dir = Path(output_path, f"experiments/{ec_level}")
        parent_dir.mkdir(parents=True, exist_ok=True)

        write_splits(df_tmp, ec_level, parent_dir)

        log.info(f"{task} complete ({len(df_tmp)} unique reactions).")


if __name__ == "__main__":
    main()
